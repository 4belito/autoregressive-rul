{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc96e3b8-ab80-4c0a-8e90-94d0b457f959",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization nominal nov 23 div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dab24df-2720-448f-a9d0-3d76d291b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('./data')\n",
    "from datautil import sys_separation,create_cross_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c64d39-ae54-47f2-893c-80fd04e89487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c3f61",
   "metadata": {},
   "source": [
    "# Choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e25e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import RUL_Transformer as arch\n",
    "\n",
    "\n",
    "from training import train_xu_y as train\n",
    "from training import evaluate_xu_y as evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49432cf8",
   "metadata": {},
   "source": [
    "# Choose data and experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83205db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name='Rectifier_nov23_4steps_perform3'\n",
    "sim_name='RectifierData_step10h' \n",
    "dataset_name='RUL_real'\n",
    "\n",
    "\n",
    "exp='rul_real'#'try_verb' # 'try' #'end2end_optim'   #  # \n",
    "verbose=False #True#\n",
    "exp_address=f'./Experiments/{data_name}/{sim_name}_{exp}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83b94e-c41e-47d5-a341-b28630cb6aa3",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2368b2d-e076-4010-acb1-4800f524e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{data_name}/dataset_{dataset_name}_train.pkl', 'rb') as file:\n",
    "    train_dataset = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb7648a1-ebb5-4412-8613-5dc57ce1b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: RUL_real\n",
      "Features (X): ['Ripple']\n",
      "-shape: (62894, 1)\n",
      "Features (U): ['clean R']\n",
      "-shape: (62894, 400, 1)\n",
      "Features (Y): ['RUL']\n",
      "-shape: (62894, 1)\n",
      "Simulation size: 400\n",
      "Number of systems: 200\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset name: {train_dataset.dataset_name}') \n",
    "for var in train_dataset.n_var:\n",
    "    if train_dataset.n_var[var]:\n",
    "        print(f'Features ({var}): {train_dataset.labels[var]}')  \n",
    "        print(f'-shape: {train_dataset.var[var].shape}')\n",
    "\n",
    "if train_dataset.n_var['U']:\n",
    "    simulation_size=train_dataset.origin['U'].shape[1]\n",
    "    print(f'Simulation size: {simulation_size}') \n",
    "print(f'Number of systems: {train_dataset.n_sys}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6c9bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 1\n",
      "Number of latents: 0\n",
      "Number of inputs: 1\n",
      "Number of outputs: 1\n"
     ]
    }
   ],
   "source": [
    "n_variables,n_latents,n_inputs,n_outputs=tuple(train_dataset.n_var.values())\n",
    "\n",
    "#_,sim_life,n_inputs=dataset.u.shape\n",
    "print(f'Number of variables: {n_variables}')\n",
    "print(f'Number of latents: {n_latents}')\n",
    "print(f'Number of inputs: {n_inputs}')\n",
    "print(f'Number of outputs: {n_outputs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e0577-23a7-46a7-96b6-73fad8282527",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyper-parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f363423",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "\n",
    "#look_backward_list=[k for k in fdrange(30)]\n",
    "#look_forward_list=[k for k in range(30)]\n",
    "batch_size=64\n",
    "stats=['X','U']\n",
    "config_loaders={'n_folds':n_folds,'batch_size':batch_size,'norm_type':'minmax','stats':stats}\n",
    "def objective(trial): \n",
    "\n",
    "    # model parameters   \n",
    "    head_dim=trial.suggest_categorical('head_dim',[32, 64, 128, 256,512,1024]) #256 256 256 64\n",
    "    n_head=trial.suggest_categorical('n_head',[1,2,4,6,8,9,10,11,12])                               #2   4  2 1\n",
    "    param=trial.suggest_categorical('embed_dim/n_head',[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])        #7 2 5 5 \n",
    "    embed_dim=param*n_head\n",
    "    dim_feedforward=trial.suggest_categorical('dim_feedforward',[16,32, 64, 128, 256, 512,1024])   #32 #32 32 512\n",
    "    p=trial.suggest_float('dropout',0,0.5) \n",
    "\n",
    "    mlp_dim1=trial.suggest_categorical('mlp_dim1',[32, 64, 128, 256,512,1024]) #256 256 256 64\n",
    "    mlp_dim2=trial.suggest_categorical('mlp_dim2',[32, 64, 128, 256,512,1024]) #256 256 256 64\n",
    "    u_enc_dim=trial.suggest_categorical('u_enc_dim',[1, 2, 4, 8,12,16])\n",
    "    mlp_dim=[mlp_dim1,mlp_dim2]\n",
    "    p_red=trial.suggest_float('p_red',0,0.5)\n",
    "\n",
    "\n",
    "    #training parameters\n",
    "    lr=trial.suggest_float('lr',1e-5,1e-3) \n",
    "    #Condition for tries\n",
    "    if exp=='try':\n",
    "        n_epoch=1\n",
    "    else:\n",
    "        n_epoch=trial.suggest_int('n_epoch',5,30) \n",
    "\n",
    "\n",
    "    # window\n",
    "    look_backward=trial.suggest_int('look_backward',29,29) #\n",
    "    #look_forward=0#trial.suggest_int('look_forward',0,0)   \n",
    "    window={'X':[look_backward,0],'Y':[0,0]}\n",
    "\n",
    "    u_input_dim=n_inputs*simulation_size\n",
    "    x_input_dim=(look_backward+1)*n_variables\n",
    "    output_dim=n_outputs\n",
    "    \n",
    "\n",
    "    # configuration\n",
    "    config_model={'input_dim':u_input_dim,\n",
    "                    'pred_window':output_dim,\n",
    "                    'embed_dim':embed_dim,\n",
    "                    'head_dim':head_dim,\n",
    "                    'dim_feedforward':dim_feedforward,\n",
    "                    'n_head':n_head,\n",
    "                    'dropout':p,\n",
    "                    'mlp_dim':mlp_dim,\n",
    "                    'u_enc_dim':u_enc_dim,\n",
    "                    'perform_w':x_input_dim,\n",
    "                    'dropout_pred':p_red\n",
    "                    }\n",
    "    \n",
    "    config_train={'n_epoch':n_epoch,'lr':lr,'window':window}\n",
    "    config_loaders.update({'window':window})\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Model: {config_model}')\n",
    "        print(f'Training: {config_train}')\n",
    "\n",
    "\n",
    "    #create loaders randomly \n",
    "    train_loaders,test_loaders=create_cross_loaders(train_dataset,**config_loaders,shuffle=True) #,train_stats   \n",
    "\n",
    "    #cross validation\n",
    "    y_preds=[]\n",
    "    y_trues=[] ##### improve this\n",
    "    weights=[]\n",
    "\n",
    "    arrays=[]\n",
    "    for fold in range(n_folds):\n",
    "        #create the model\n",
    "\n",
    "\n",
    "        #create the model\n",
    "        model=arch(**config_model).to(device).double() \n",
    "\n",
    "        #train and evaluate model on fold \n",
    "\n",
    "        model_trained=train(model,train_loaders[fold],**config_train,verbose=verbose)\n",
    "        weight=copy.deepcopy(model_trained.state_dict()) \n",
    "\n",
    "        y_pred,y_true=evaluate(model_trained,test_loaders[fold],window=window,verbose=verbose)\n",
    "        \n",
    "        #save folds predictions\n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(y_true)\n",
    "        weights.append(weight)\n",
    "        arrays.append(test_loaders[fold].dataset.sys_array)\n",
    "\n",
    "    y_pred=np.concatenate(y_preds,axis=0)\n",
    "    y_true=np.concatenate(y_trues,axis=0)\n",
    "    \n",
    "    array=np.concatenate(arrays)\n",
    "    \n",
    "    #System separation\n",
    "    y_pred_sep=sys_separation(y_pred,array)\n",
    "    y_true_sep=sys_separation(y_true,array)\n",
    "\n",
    "    #RMSE\n",
    "    RMSE_sys=np.sqrt(np.nanmean((y_pred_sep-y_true_sep)**2,axis=tuple(range(1,y_pred_sep.ndim))))\n",
    "    RMSE_mean=np.mean(RMSE_sys,axis=0)\n",
    "    #RMSE_std=np.std(RMSE_sys,axis=0)\n",
    "\n",
    "    #scoring\n",
    "    # Nasa_scoring_sys=np.nanmean(scoring(y_pred,y_true),axis=1)\n",
    "    # Nasa_scoring_mean=np.nanmean(Nasa_scoring_sys,axis=0)\n",
    "    # Nasa_scoring_std=np.nanstd(Nasa_scoring_sys,axis=0)\n",
    "    \n",
    "    # score=0.5*RMSE_mean+0.5*Nasa_scoring_mean\n",
    "    \n",
    "    if trial.number==0 or study.best_trial.value >= RMSE_mean:\n",
    "        torch.save(train_loaders, f'{exp_address}/train_loaders.pkl')\n",
    "        torch.save(test_loaders, f'{exp_address}/test_loaders.pkl')\n",
    "        torch.save(weights, f'{exp_address}/best_model1.pt')\n",
    "        config={'loaders':config_loaders,'model':config_model,'train':config_train}\n",
    "        torch.save(config, f'{exp_address}/best_config.pt')\n",
    "    return RMSE_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630293f5-675b-41a2-b2fd-bc69adc512c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-19 19:49:02,629] Using an existing study with name './Experiments/Rectifier_nov23_4steps_perform3/RectifierData_step10h_rul_real/estudio' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_name = exp_address+'/estudio' #f\"{dataset_name}_test{test}\"\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "\n",
    "os.makedirs(f'{exp_address}', exist_ok=True)\n",
    "study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "len(study.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7ef211-cfca-4047-b8aa-3b731a9bb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials=100\n",
    "study.optimize(objective, n_trials=n_trials-len(study.trials), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab5c69a-b554-45d5-9f8e-59da0cee6e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head_dim': 32,\n",
       " 'n_head': 6,\n",
       " 'embed_dim/n_head': 12,\n",
       " 'dim_feedforward': 128,\n",
       " 'dropout': 0.47787675008320984,\n",
       " 'mlp_dim1': 1024,\n",
       " 'mlp_dim2': 1024,\n",
       " 'u_enc_dim': 2,\n",
       " 'p_red': 0.2256869271809978,\n",
       " 'lr': 0.0009524868575007632,\n",
       " 'n_epoch': 28,\n",
       " 'look_backward': 29}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f294e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.483713908864895"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b04df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008ba62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25411d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab681cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb85bf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc28f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7188c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f41b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c05e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
